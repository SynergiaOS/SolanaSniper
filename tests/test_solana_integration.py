#!/usr/bin/env python3
"""
ðŸ”— SOLANA INTEGRATION TESTS for SolanaSniper 3.0
===============================================

Integration tests specifically for Solana blockchain interactions.
Tests agent communication, transaction handling, and DeFi protocol integration.

Requirements:
- solana-test-validator running locally
- Test SOL tokens for devnet testing
- DragonflyDB for agent communication

Test Scenarios:
- Agent-to-Agent communication via DragonflyDB
- Solana transaction simulation on devnet
- DEX integration testing (Raydium, Orca)
- Wallet management and security
- Real-time data processing pipeline

Target: Reduce MTTR from 45s to <30s through better integration testing
"""

import pytest
import asyncio
import json
import subprocess
import time
from unittest.mock import AsyncMock, patch, MagicMock
from datetime import datetime, timedelta
from typing import Dict, List, Any
import redis.asyncio as redis

# Test markers
pytestmark = [pytest.mark.integration, pytest.mark.solana]


class SolanaTestEnvironment:
    """Manages Solana test environment setup"""
    
    def __init__(self):
        self.validator_process = None
        self.test_wallet = None
        self.redis_client = None
    
    async def setup(self):
        """Setup test environment"""
        print("ðŸš€ Setting up Solana test environment...")
        
        # Start test validator
        await self.start_test_validator()
        
        # Setup test wallet
        await self.setup_test_wallet()
        
        # Connect to DragonflyDB
        await self.connect_to_dragonfly()
        
        print("âœ… Test environment ready!")
    
    async def start_test_validator(self):
        """Start solana-test-validator"""
        try:
            # Check if validator is already running
            result = subprocess.run(
                ["solana", "cluster-version"],
                capture_output=True,
                text=True,
                timeout=5
            )
            
            if result.returncode == 0:
                print("âœ… Solana test validator already running")
                return
            
        except (subprocess.TimeoutExpired, FileNotFoundError):
            pass
        
        # Start new validator
        print("ðŸ”„ Starting solana-test-validator...")
        self.validator_process = subprocess.Popen([
            "solana-test-validator",
            "--reset",
            "--quiet"
        ])
        
        # Wait for validator to be ready
        await asyncio.sleep(5)
        print("âœ… Solana test validator started")
    
    async def setup_test_wallet(self):
        """Setup test wallet with SOL"""
        try:
            # Generate test keypair
            result = subprocess.run([
                "solana-keygen", "new", 
                "--outfile", "/tmp/test-wallet.json",
                "--no-bip39-passphrase", "--force"
            ], capture_output=True, text=True)
            
            if result.returncode == 0:
                # Airdrop test SOL
                subprocess.run([
                    "solana", "airdrop", "10",
                    "--keypair", "/tmp/test-wallet.json"
                ], capture_output=True)
                
                self.test_wallet = "/tmp/test-wallet.json"
                print("âœ… Test wallet created with 10 SOL")
            
        except Exception as e:
            print(f"âš ï¸ Wallet setup failed: {e}")
            # Use mock wallet for testing
            self.test_wallet = "mock_wallet"
    
    async def connect_to_dragonfly(self):
        """Connect to DragonflyDB for agent communication"""
        try:
            self.redis_client = redis.Redis(
                host='localhost',
                port=6379,
                decode_responses=True
            )
            
            # Test connection
            await self.redis_client.ping()
            print("âœ… Connected to DragonflyDB")
            
        except Exception as e:
            print(f"âš ï¸ DragonflyDB connection failed: {e}")
            # Use mock client
            self.redis_client = AsyncMock()
    
    async def cleanup(self):
        """Cleanup test environment"""
        if self.validator_process:
            self.validator_process.terminate()
            self.validator_process.wait()
        
        if self.redis_client and hasattr(self.redis_client, 'close'):
            await self.redis_client.close()
        
        print("ðŸ§¹ Test environment cleaned up")


class TestAgentCommunication:
    """Test A2A Protocol communication via DragonflyDB"""
    
    @pytest.fixture
    async def test_env(self):
        """Setup test environment"""
        env = SolanaTestEnvironment()
        await env.setup()
        yield env
        await env.cleanup()
    
    @pytest.mark.asyncio
    async def test_scout_to_analyst_communication(self, test_env):
        """Test: Scout Agent -> Analyst Agent communication"""
        # Mock opportunity data
        opportunity = {
            'id': 'test_opp_001',
            'title': 'Solana DEX launches with innovative AMM',
            'score': 28,
            'source': 'DeFiPulse',
            'timestamp': datetime.now().isoformat(),
            'metadata': {
                'token_address': 'So11111111111111111111111111111111111111112',
                'liquidity': 50000,
                'volume_24h': 100000
            }
        }
        
        # Simulate Scout Agent publishing opportunity
        channel = 'opportunities'
        await test_env.redis_client.publish(channel, json.dumps(opportunity))
        
        # Simulate Analyst Agent receiving opportunity
        pubsub = test_env.redis_client.pubsub()
        await pubsub.subscribe(channel)
        
        # Wait for message
        message = await pubsub.get_message(timeout=5.0)
        
        if message and message['type'] == 'message':
            received_data = json.loads(message['data'])
            
            assert received_data['id'] == 'test_opp_001'
            assert received_data['score'] == 28
            assert 'Solana DEX' in received_data['title']
            
            print("âœ… Scout -> Analyst communication successful")
        else:
            pytest.fail("No message received from Scout Agent")
    
    @pytest.mark.asyncio
    async def test_analyst_to_risk_communication(self, test_env):
        """Test: Analyst Agent -> Risk Agent communication"""
        # Mock analysis result
        analysis = {
            'opportunity_id': 'test_opp_001',
            'analysis': {
                'sentiment': 'bullish',
                'confidence': 0.85,
                'risk_factors': ['new protocol', 'limited audit'],
                'opportunity_type': 'dex_launch',
                'predicted_impact': 'medium'
            },
            'ai_model': 'deepseek-reasoner',
            'timestamp': datetime.now().isoformat()
        }
        
        # Publish analysis
        channel = 'analysis_reports'
        await test_env.redis_client.publish(channel, json.dumps(analysis))
        
        # Simulate Risk Agent processing
        pubsub = test_env.redis_client.pubsub()
        await pubsub.subscribe(channel)
        
        message = await pubsub.get_message(timeout=5.0)
        
        if message and message['type'] == 'message':
            received_analysis = json.loads(message['data'])
            
            assert received_analysis['analysis']['sentiment'] == 'bullish'
            assert received_analysis['analysis']['confidence'] == 0.85
            assert 'new protocol' in received_analysis['analysis']['risk_factors']
            
            print("âœ… Analyst -> Risk communication successful")
        else:
            pytest.fail("No analysis received from Analyst Agent")
    
    @pytest.mark.asyncio
    async def test_risk_to_executor_communication(self, test_env):
        """Test: Risk Agent -> Executor Agent communication"""
        # Mock risk assessment
        risk_assessment = {
            'opportunity_id': 'test_opp_001',
            'decision': 'GO',
            'risk_score': 0.75,
            'position_size': 0.5,  # 0.5 SOL
            'max_slippage': 0.03,
            'stop_loss': 0.95,
            'take_profit': 1.15,
            'reasoning': 'Low risk, good liquidity, positive sentiment',
            'timestamp': datetime.now().isoformat()
        }
        
        # Publish risk assessment
        channel = 'execution_orders'
        await test_env.redis_client.publish(channel, json.dumps(risk_assessment))
        
        # Simulate Executor Agent receiving order
        pubsub = test_env.redis_client.pubsub()
        await pubsub.subscribe(channel)
        
        message = await pubsub.get_message(timeout=5.0)
        
        if message and message['type'] == 'message':
            received_order = json.loads(message['data'])
            
            assert received_order['decision'] == 'GO'
            assert received_order['position_size'] == 0.5
            assert received_order['risk_score'] == 0.75
            
            print("âœ… Risk -> Executor communication successful")
        else:
            pytest.fail("No order received from Risk Agent")


class TestSolanaTransactions:
    """Test Solana blockchain transaction handling"""
    
    @pytest.fixture
    async def test_env(self):
        """Setup test environment"""
        env = SolanaTestEnvironment()
        await env.setup()
        yield env
        await env.cleanup()
    
    @pytest.mark.asyncio
    async def test_wallet_balance_check(self, test_env):
        """Test: Wallet balance verification"""
        if test_env.test_wallet == "mock_wallet":
            # Mock balance check
            balance = 10.0  # 10 SOL
            assert balance > 0
            print("âœ… Mock wallet balance check successful")
            return
        
        try:
            # Real balance check
            result = subprocess.run([
                "solana", "balance",
                "--keypair", test_env.test_wallet
            ], capture_output=True, text=True, timeout=10)
            
            if result.returncode == 0:
                balance_str = result.stdout.strip()
                balance = float(balance_str.split()[0])
                
                assert balance > 0, f"Insufficient balance: {balance} SOL"
                print(f"âœ… Wallet balance: {balance} SOL")
            else:
                pytest.fail(f"Balance check failed: {result.stderr}")
                
        except Exception as e:
            pytest.fail(f"Balance check error: {e}")
    
    @pytest.mark.asyncio
    async def test_transaction_simulation(self, test_env):
        """Test: Transaction simulation (dry run)"""
        # Mock transaction data
        transaction_data = {
            'from_wallet': test_env.test_wallet,
            'to_address': 'So11111111111111111111111111111111111111112',  # SOL token
            'amount': 0.1,  # 0.1 SOL
            'operation': 'swap',
            'dex': 'raydium'
        }
        
        # Simulate transaction building
        def simulate_transaction_build(tx_data):
            return {
                'success': True,
                'estimated_fee': 0.000005,  # 5000 lamports
                'estimated_gas': 200000,
                'slippage_impact': 0.02,
                'transaction_size': 1232,  # bytes
                'simulation_result': 'success'
            }
        
        result = simulate_transaction_build(transaction_data)
        
        assert result['success'] is True
        assert result['estimated_fee'] < 0.001  # Less than 0.001 SOL fee
        assert result['slippage_impact'] < 0.05  # Less than 5% slippage
        
        print("âœ… Transaction simulation successful")
    
    @pytest.mark.asyncio
    async def test_dex_integration_mock(self, test_env):
        """Test: DEX integration (mocked)"""
        # Mock DEX interaction
        dex_request = {
            'dex': 'raydium',
            'operation': 'swap',
            'input_token': 'SOL',
            'output_token': 'USDC',
            'amount': 1.0,
            'slippage': 0.01
        }
        
        def mock_dex_interaction(request):
            # Simulate DEX response
            return {
                'success': True,
                'input_amount': request['amount'],
                'output_amount': request['amount'] * 100,  # 1 SOL = 100 USDC (mock rate)
                'actual_slippage': 0.005,  # 0.5% actual slippage
                'fee': 0.003,  # 0.3% fee
                'transaction_hash': 'mock_tx_hash_12345',
                'block_height': 123456789
            }
        
        result = mock_dex_interaction(dex_request)
        
        assert result['success'] is True
        assert result['output_amount'] == 100.0  # Expected USDC amount
        assert result['actual_slippage'] <= dex_request['slippage']
        
        print("âœ… DEX integration test successful")


class TestPerformanceRecovery:
    """Test system performance and recovery capabilities"""
    
    @pytest.mark.asyncio
    async def test_agent_recovery_time(self):
        """Test: Agent recovery time measurement"""
        start_time = time.time()
        
        # Simulate agent failure and recovery
        async def simulate_agent_failure_recovery():
            # Simulate failure
            await asyncio.sleep(0.1)  # 100ms failure detection
            
            # Simulate recovery process
            recovery_steps = [
                ('reconnect_dragonfly', 0.5),
                ('reload_config', 0.3),
                ('restart_agent', 0.8),
                ('verify_health', 0.2)
            ]
            
            for step, duration in recovery_steps:
                await asyncio.sleep(duration)
                print(f"  {step}: {duration}s")
        
        await simulate_agent_failure_recovery()
        
        recovery_time = time.time() - start_time
        
        # Target: <30s recovery time
        assert recovery_time < 30.0, f"Recovery time too slow: {recovery_time:.2f}s"
        
        print(f"âœ… Agent recovery time: {recovery_time:.2f}s (target: <30s)")
    
    @pytest.mark.asyncio
    async def test_communication_latency(self):
        """Test: A2A communication latency"""
        latencies = []
        
        # Test multiple message round trips
        for i in range(10):
            start = time.time()
            
            # Simulate message send/receive
            await asyncio.sleep(0.001)  # 1ms simulated network latency
            
            latency = (time.time() - start) * 1000  # Convert to ms
            latencies.append(latency)
        
        avg_latency = sum(latencies) / len(latencies)
        max_latency = max(latencies)
        
        # Target: <100ms average latency
        assert avg_latency < 100, f"High average latency: {avg_latency:.2f}ms"
        assert max_latency < 200, f"High max latency: {max_latency:.2f}ms"
        
        print(f"âœ… Communication latency - Avg: {avg_latency:.2f}ms, Max: {max_latency:.2f}ms")


@pytest.mark.asyncio
async def test_end_to_end_pipeline():
    """Test: Complete end-to-end trading pipeline"""
    print("ðŸ”„ Testing end-to-end pipeline...")
    
    # Setup test environment
    env = SolanaTestEnvironment()
    await env.setup()
    
    try:
        pipeline_start = time.time()
        
        # Step 1: Scout detects opportunity
        opportunity = {
            'id': 'e2e_test_001',
            'title': 'Major Solana DeFi protocol announces token launch',
            'score': 35,
            'confidence': 0.9
        }
        
        await env.redis_client.publish('opportunities', json.dumps(opportunity))
        await asyncio.sleep(0.1)  # Processing time
        
        # Step 2: Analyst analyzes opportunity
        analysis = {
            'opportunity_id': 'e2e_test_001',
            'sentiment': 'very_bullish',
            'confidence': 0.92,
            'recommendation': 'strong_buy'
        }
        
        await env.redis_client.publish('analysis_reports', json.dumps(analysis))
        await asyncio.sleep(0.1)  # Processing time
        
        # Step 3: Risk assesses and approves
        risk_decision = {
            'opportunity_id': 'e2e_test_001',
            'decision': 'GO',
            'position_size': 0.8,
            'risk_score': 0.85
        }
        
        await env.redis_client.publish('execution_orders', json.dumps(risk_decision))
        await asyncio.sleep(0.1)  # Processing time
        
        # Step 4: Executor simulates trade
        execution_result = {
            'opportunity_id': 'e2e_test_001',
            'status': 'completed',
            'transaction_hash': 'mock_hash_e2e',
            'profit': 0.05  # 5% profit
        }
        
        await env.redis_client.publish('trade_results', json.dumps(execution_result))
        
        pipeline_duration = time.time() - pipeline_start
        
        # Verify pipeline completed successfully
        assert pipeline_duration < 5.0, f"Pipeline too slow: {pipeline_duration:.2f}s"
        assert execution_result['status'] == 'completed'
        assert execution_result['profit'] > 0
        
        print(f"âœ… End-to-end pipeline completed in {pipeline_duration:.2f}s")
        
    finally:
        await env.cleanup()


if __name__ == "__main__":
    # Run integration tests
    pytest.main([
        __file__,
        "-v",
        "-m", "integration",
        "--tb=short"
    ])
